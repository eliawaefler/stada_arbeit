# seiten/pca.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

def show(df):
    st.title("ğŸ§® PCA â€“ Hauptkomponentenanalyse")

    st.write("""
    Die Hauptkomponentenanalyse (PCA) reduziert viele Variablen auf wenige Komponenten,  
    die mÃ¶glichst viel Varianz der ursprÃ¼nglichen Daten erklÃ¤ren.  
    Ziel: Muster erkennen, Dimension reduzieren, Visualisierung verbessern.
    """)

    # Zeitliche Zusatzfeatures
    df = df.copy()
    df["weekday"] = df["DATUM"].dt.weekday
    df["hour"] = df["DATUM"].dt.hour

    default_features = [
        "VELO_IN", "VELO_OUT", "FUSS_IN", "FUSS_OUT",
        "temp", "humidity", "wind_speed", "clouds_all",
        "dew_point", "feels_like", "pressure", "visibility",
        "weekday", "hour"
    ]

    st.subheader("ğŸ“Œ Variablenauswahl")
    st.write("WÃ¤hle die numerischen Variablen aus, die du in die PCA einbeziehen mÃ¶chtest.")
    selected = st.multiselect("Variablen fÃ¼r PCA", default_features, default=default_features)

    if len(selected) < 2:
        st.warning("Bitte mindestens zwei Variablen auswÃ¤hlen.")
        return

    df_pca = df[selected].dropna()
    X_scaled = StandardScaler().fit_transform(df_pca)

    # PCA-Komponentenanzahl
    st.subheader("âš™ï¸ Anzahl Hauptkomponenten")
    st.write("WÃ¤hle, wie viele Hauptkomponenten berechnet werden sollen (mind. 2 fÃ¼r Visualisierung).")
    n_components = st.slider("Anzahl Hauptkomponenten", 2, min(len(selected), 10), value=2)

    pca = PCA(n_components=n_components)
    components = pca.fit_transform(X_scaled)

    explained_var = pca.explained_variance_ratio_
    pc_names = [f"PC{i+1}" for i in range(n_components)]
    pca_df = pd.DataFrame(components, columns=pc_names)

    # -------------------
    st.subheader("ğŸ”µ 2D PCA Scatterplot")
    st.write("""
    Die ersten zwei Hauptkomponenten werden dargestellt.  
    Jeder Punkt entspricht einem Zeitpunkt (Stunde) mit bestimmten Bewegungs- und Wetterwerten.
    """)
    st.scatter_chart(pca_df[["PC1", "PC2"]])

    # -------------------
    st.subheader("ğŸ“ˆ ErklÃ¤rte Varianz")
    st.write("""
    Zeigt, wie viel Prozent der Gesamtvarianz durch jede Hauptkomponente erklÃ¤rt werden.  
    Hohe Werte fÃ¼r PC1 und PC2 sind ideal fÃ¼r eine 2D-Darstellung.
    """)
    for i, var in enumerate(explained_var):
        st.write(f"{pc_names[i]}: {var:.2%}")

    # -------------------
    st.subheader("ğŸ“ Einflussrichtungen (Loadings) auf PC1 & PC2")
    st.write("""
    Die Richtung und LÃ¤nge der Pfeile zeigen, wie stark ein ursprÃ¼ngliches Merkmal  
    zu PC1 und PC2 beitrÃ¤gt.  
    Je lÃ¤nger ein Pfeil, desto mehr Varianz dieses Merkmals wird durch diese PCs erklÃ¤rt.
    
    Pfeile mit Ã¤hnlicher Richtung â†’ stark positiv korrelierte Variablen
    Pfeile in entgegengesetzte Richtung â†’ negativ korreliert
    Pfeile senkrecht zueinander â†’ unkorreliert
    Punkte, die in Richtung eines Pfeils liegen â†’ dort dominiert dieses Merkmal
    """)

    fig, ax = plt.subplots(figsize=(6, 6))
    for i, feature in enumerate(selected):
        ax.arrow(0, 0,
                 pca.components_[0, i],
                 pca.components_[1, i],
                 head_width=0.05, head_length=0.05, fc='blue', ec='blue')
        ax.text(pca.components_[0, i]*1.1,
                pca.components_[1, i]*1.1,
                feature,
                color='black', ha='center', va='center')

    ax.set_xlabel("PC1")
    ax.set_ylabel("PC2")
    ax.set_title("PCA â€“ Einfluss der Merkmale auf die ersten zwei PCs")
    ax.grid(True)
    ax.axhline(0, color='grey', lw=1)
    ax.axvline(0, color='grey', lw=1)
    ax.set_xlim(-1, 1)
    ax.set_ylim(-1, 1)
    st.pyplot(fig)
